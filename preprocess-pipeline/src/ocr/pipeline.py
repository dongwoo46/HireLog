import os
from ocr.preprocess import preprocess_image
from ocr.engine import run_ocr
from ocr.lines import build_lines
from normalize.pipeline import normalize_lines
from ocr.postprocess import postprocess_ocr_lines
from utils.rawtext import build_raw_text
from ocr.confidence import classify_confidence
from ocr.quality import filter_low_quality_lines
from ocr.header_detector import detect_visual_headers

def process_ocr_input(image_input: str | list[str]):
    """
    OCR ì…ë ¥ íŒŒì´í”„ë¼ì¸ ë‹¨ì¼ ì§„ì…ì 

    ëª©ì :
    - ì™¸ë¶€ ì…ë ¥(image path or list of paths)ì„ JD ë¶„ì„ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    - OCR í’ˆì§ˆ ìƒíƒœë¥¼ í•¨ê»˜ ë°˜í™˜
    - ì—¬ëŸ¬ ì´ë¯¸ì§€(í˜ì´ì§€)ì¸ ê²½ìš° ê²°ê³¼ë¥¼ ë³‘í•©í•˜ì—¬ ë°˜í™˜

    ì²˜ë¦¬ íë¦„:
    1. ì…ë ¥ ì •ê·œí™” (Single str -> List[str])
    2. ê° ì´ë¯¸ì§€ë³„ _process_single_image ì‹¤í–‰
    3. ê²°ê³¼ ë³‘í•© (Text, Lines, Confidence)
    """

    # 1. ì…ë ¥ ì •ê·œí™”
    image_paths = normalize_image_paths(image_input)

    if not image_paths:
        return _fail("no image paths provided")

    # 2. ì´ë¯¸ì§€ë³„ ì²˜ë¦¬ ë° ìˆ˜ì§‘
    aggregated_raw_texts = []
    aggregated_lines = []
    confidences = []
    errors = []



    for path in image_paths:
        result = _process_single_image(path)

        if result.get("error"):
            errors.append({
                "path": path,
                "error": result["error"],
            })
            continue
        
        # ì‹¤íŒ¨í–ˆë”ë¼ë„ ë¶€ë¶„ ê²°ê³¼ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³‘í•© ì§„í–‰
        # (ì™„ì „ ì‹¤íŒ¨ ì‹œ rawText="", lines=[]ì¼ ê²ƒì„)
        if result["rawText"]:
            aggregated_raw_texts.append(result["rawText"])
        
        if result["lines"]:
            aggregated_lines.extend(result["lines"])
            
        # ConfidenceëŠ” ì„±ê³µ/ì‹¤íŒ¨ ë¬´ê´€í•˜ê²Œ ê³„ì‚°ëœ ê°’ì´ë©´ ìˆ˜ì§‘ (0.0 ì œì™¸?)
        if result["confidence"] > 0:
            confidences.append(result["confidence"])

    # 3. ê²°ê³¼ ë³‘í•©
    final_raw_text = "\n\n".join(aggregated_raw_texts)
    
    # í‰ê·  Confidence ê³„ì‚°
    final_confidence = sum(confidences) / len(confidences) if confidences else 0.0
    
    # ìµœì¢… Status íŒì • (Enum â†’ str ë³€í™˜)
    final_status = classify_confidence(final_confidence).value

    return {
        "rawText": final_raw_text,     # ì‚¬ëŒì´ ì½ëŠ” ìš©ë„ (í˜ì´ì§€ êµ¬ë¶„ë¨)
        "lines": aggregated_lines,     # ğŸ‘‰ JD íŒŒì´í”„ë¼ì¸ ì…ë ¥ìš© (ìˆœì„œëŒ€ë¡œ ì—°ê²°)
        "confidence": final_confidence,
        "status": final_status,
        "errors": errors,
    }

def _fail(reason: str) -> dict:
    return {
        "rawText": "",
        "lines": [],
        "confidence": 0.0,
        "status": "FAIL",
        "error": reason,
    }

def _process_single_image(image_path: str) -> dict:

    # ==================================================
    # 0ï¸âƒ£ ì…ë ¥ ê²½ë¡œ ê²€ì¦ (ì¤‘ìš”)
    # ==================================================
    if not isinstance(image_path, str):
        return _fail("image_path is not a string")

    if not os.path.exists(image_path):
        return _fail(f"image not found: {image_path}")

    if not os.path.isfile(image_path):
        return _fail(f"image_path is not a file: {image_path}")

    if not os.access(image_path, os.R_OK):
        return _fail(f"image not readable: {image_path}")

    """
    ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ OCR ì²˜ë¦¬
    """
    # 1 ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    try:
        preprocessed_image = preprocess_image(image_path)
    except Exception as e:
        # ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ë“±
        return _fail(f"preprocess_image failed: {e}")

    # 2ï¸ OCR ì‹¤í–‰
    ocr_result = run_ocr(preprocessed_image)
    if not ocr_result.get("raw"):
        return _fail("ocr returned empty raw result")
    # # ğŸ” DEBUG 1: OCR RAW (PaddleOCR ì›ë³¸)
    # print("\n=== [DEBUG 1] OCR RAW ITEMS ===")
    # for i, item in enumerate(ocr_result["raw"]):
    #     print(f"[{i:03d}] text='{item.get('text', '')}' conf={item.get('confidence')}")
    # print("================================\n")

    # 2.5ï¸âƒ£ OCR RAW â†’ LINE êµ¬ì¡°í™” (ì•„ì§ ê°€ê³µ ì—†ìŒ)
    lines = build_lines(ocr_result["raw"])
    # print("\n=== [DEBUG 2] AFTER build_lines ===")
    # for i, line in enumerate(lines):
    #     print(f"[{i:03d}] '{line.get('text', '')}'")
    # print("=================================\n")

    # 3ï¸âƒ£ í—¤ë” ê°ì§€
    lines = detect_visual_headers(lines)
    # print("\n=== [DEBUG 3] AFTER detect_visual_headers ===")
    # for i, line in enumerate(lines):
    #     header_flag = line.get("is_header")
    #     print(f"[{i:03d}] '{line.get('text', '')}' header={header_flag}")
    # print("============================================\n")

    # 4. ë¼ì¸ ë‹¨ìœ„ normalize íŒŒì´í”„ë¼ì¸
    normalized = normalize_lines(lines)

    # â­ 4.5 ë¼ì¸ ë‹¨ìœ„ í’ˆì§ˆ ê²Œì´íŠ¸ (ì´ˆê¸° ì°¨ë‹¨)
    # - confidence ë‚®ì€ ë¼ì¸
    # - garbage ë¹„ìœ¨ ë†’ì€ ë¼ì¸
    # - ì¢Œí‘œ ì´ìƒ ë¼ì¸ ì œê±°/ê²©ë¦¬
    passed_lines, dropped_lines = filter_low_quality_lines(
        normalized,
        min_confidence=45,          # ì„ì‹œ ê¸°ì¤€
        max_garbage_ratio=0.6       # ì„ì‹œ ê¸°ì¤€
    )

    # dump_tmp_data("pass_lines", passed_lines)
    # dump_tmp_data("dropped_lines", dropped_lines)

    # 5. ocrë¡œ ì²˜ë¦¬í•œ raw ë°ì´í„° í›„ì²˜ë¦¬
    ocr_lines = postprocess_ocr_lines(passed_lines)

    # 6. ìµœì¢… rawText ìƒì„±
    raw_text = build_raw_text(ocr_lines)

    # 7. OCR í’ˆì§ˆ ìƒíƒœ ë¶„ë¥˜ (Enum â†’ str ë³€í™˜)
    status = classify_confidence(ocr_result["confidence"]).value

    return {
        "rawText": raw_text,     # ì‚¬ëŒì´ ì½ëŠ” ìš©ë„
        "lines": ocr_lines,       # ğŸ‘‰ JD íŒŒì´í”„ë¼ì¸ ì…ë ¥ìš© (ì¤‘ìš”)
        "confidence": ocr_result["confidence"],
        "status": status,
    }

def normalize_image_paths(image_input) -> list[str]:
    """
    image_input ì •ê·œí™”

    í—ˆìš© í¬ë§·:
    - str (comma-separated)
    - list[str]
    - list[str] where element itself contains comma
    """

    paths: list[str] = []

    if isinstance(image_input, str):
        paths = image_input.split(",")

    elif isinstance(image_input, list):
        for item in image_input:
            if not item:
                continue

            if "," in item:
                paths.extend(item.split(","))
            else:
                paths.append(item)

    return [p.strip() for p in paths if p.strip()]
